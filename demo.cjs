/**
 * OpenCC åè®®è½¬æ¢å™¨ - ç®€åŒ–æ¼”ç¤ºç‰ˆæœ¬
 * 
 * è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¼”ç¤ºç‰ˆæœ¬ï¼Œå±•ç¤ºäº†æ ¸å¿ƒè½¬æ¢é€»è¾‘
 * å®Œæ•´çš„TypeScriptç‰ˆæœ¬åœ¨src/ç›®å½•ä¸­
 */

const express = require('express');
const cors = require('cors');

const app = express();
const PORT = process.env.PORT || 3000;

// ä¸­é—´ä»¶
app.use(cors());
app.use(express.json());

// æ¨¡å‹æ˜ å°„é…ç½®
const MODEL_MAPPING = {
  'claude-3-opus-20240229': {
    openaiModel: 'gpt-4-turbo-preview',
    contextLength: 128000,
    maxTokens: 4096,
    capabilities: ['text', 'images', 'tools', 'reasoning']
  },
  'claude-3-sonnet-20240229': {
    openaiModel: 'gpt-4',
    contextLength: 8192,
    maxTokens: 4096,
    capabilities: ['text', 'images', 'tools', 'balanced']
  },
  'claude-3-haiku-20240307': {
    openaiModel: 'gpt-3.5-turbo',
    contextLength: 16384,
    maxTokens: 4096,
    capabilities: ['text', 'images', 'speed']
  }
};

// å·¥å…·å‡½æ•°
function generateMessageId() {
  return `msg_${Math.random().toString(36).substring(2, 15)}`;
}

function flattenContent(content) {
  if (typeof content === 'string') {
    return content;
  }
  
  if (Array.isArray(content)) {
    return content
      .filter(item => item.type === 'text')
      .map(item => item.text || '')
      .join('\n');
  }
  
  return '';
}

// æ£€æŸ¥ä¸æ”¯æŒçš„å†…å®¹
function hasUnsupportedContent(content) {
  if (!Array.isArray(content)) {
    return { hasUnsupported: false, unsupportedTypes: [] };
  }
  
  const unsupportedTypes = content
    .map(item => item.type)
    .filter(type => ['input_audio', 'file'].includes(type));
    
  return {
    hasUnsupported: unsupportedTypes.length > 0,
    unsupportedTypes: [...new Set(unsupportedTypes)]
  };
}

// Anthropicåˆ°OpenAIè¯·æ±‚è½¬æ¢
function convertAnthropicToOpenAI(anthropicRequest) {
  // éªŒè¯å¿…éœ€å‚æ•°
  if (!anthropicRequest.model) {
    throw new Error('Missing required parameter: model');
  }
  
  if (!anthropicRequest.max_tokens || anthropicRequest.max_tokens <= 0) {
    throw new Error('Missing or invalid required parameter: max_tokens');
  }
  
  if (!anthropicRequest.messages || anthropicRequest.messages.length === 0) {
    throw new Error('Missing or empty required parameter: messages');
  }
  
  // æ£€æŸ¥æ¨¡å‹æ”¯æŒ
  const modelMapping = MODEL_MAPPING[anthropicRequest.model];
  if (!modelMapping) {
    throw new Error(`Unsupported model: ${anthropicRequest.model}`);
  }
  
  // æ£€æŸ¥ä¸æ”¯æŒçš„å†…å®¹
  for (const message of anthropicRequest.messages) {
    if (Array.isArray(message.content)) {
      const { hasUnsupported, unsupportedTypes } = hasUnsupportedContent(message.content);
      if (hasUnsupported) {
        const typeMessage = unsupportedTypes.includes('input_audio') ? 
          'éŸ³é¢‘è¾“å…¥åŠŸèƒ½æš‚ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨çº¯æ–‡æœ¬è¾“å…¥' :
          'æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æš‚ä¸æ”¯æŒï¼Œè¯·å°†æ–‡ä»¶å†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬åè¾“å…¥';
        throw new Error(typeMessage);
      }
    }
  }
  
  // æ„å»ºOpenAIè¯·æ±‚
  const openaiMessages = [];
  
  // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
  if (anthropicRequest.system) {
    openaiMessages.push({
      role: 'system',
      content: anthropicRequest.system
    });
  }
  
  // è½¬æ¢æ¶ˆæ¯
  for (const message of anthropicRequest.messages) {
    openaiMessages.push({
      role: message.role,
      content: flattenContent(message.content)
    });
  }
  
  return {
    model: modelMapping.openaiModel,
    messages: openaiMessages,
    max_tokens: Math.min(anthropicRequest.max_tokens, modelMapping.maxTokens),
    temperature: anthropicRequest.temperature,
    top_p: anthropicRequest.top_p,
    stream: anthropicRequest.stream
  };
}

// OpenAIåˆ°Anthropicå“åº”è½¬æ¢
function convertOpenAIToAnthropic(openaiResponse, originalModel) {
  const choice = openaiResponse.choices[0];
  if (!choice) {
    throw new Error('No choices in OpenAI response');
  }
  
  // è½¬æ¢åœæ­¢åŸå› 
  const stopReasonMap = {
    'stop': 'end_turn',
    'length': 'max_tokens',
    'tool_calls': 'tool_use',
    'content_filter': 'end_turn'
  };
  
  return {
    id: generateMessageId(),
    type: 'message',
    role: 'assistant',
    content: [
      {
        type: 'text',
        text: choice.message.content || ''
      }
    ],
    model: originalModel,
    stop_reason: stopReasonMap[choice.finish_reason] || 'end_turn',
    usage: {
      input_tokens: openaiResponse.usage.prompt_tokens,
      output_tokens: openaiResponse.usage.completion_tokens
    }
  };
}

// è·¯ç”±å®šä¹‰

// æ ¹ç«¯ç‚¹
app.get('/', (req, res) => {
  res.json({
    name: 'OpenCC Protocol Converter',
    version: '1.0.0',
    description: 'Anthropic Claude API to OpenAI API protocol converter',
    status: 'online',
    endpoints: {
      messages: '/v1/messages',
      models: '/v1/models',
      health: '/health'
    },
    note: 'This is a demo version. Full TypeScript implementation is in src/ directory.'
  });
});

// å¥åº·æ£€æŸ¥
app.get('/health', (req, res) => {
  res.json({
    status: 'healthy',
    timestamp: Date.now(),
    version: '1.0.0-demo',
    uptime: process.uptime(),
    memory: {
      used: process.memoryUsage().heapUsed,
      total: process.memoryUsage().heapTotal,
      percentage: Math.round((process.memoryUsage().heapUsed / process.memoryUsage().heapTotal) * 100)
    }
  });
});

// æ¨¡å‹åˆ—è¡¨
app.get('/v1/models', (req, res) => {
  const models = Object.entries(MODEL_MAPPING).map(([id, mapping]) => ({
    id,
    object: 'model',
    created: 1677610602,
    owned_by: 'anthropic',
    capabilities: mapping.capabilities,
    context_length: mapping.contextLength,
    max_tokens: mapping.maxTokens,
    mapped_to: mapping.openaiModel
  }));
  
  res.json({
    object: 'list',
    data: models
  });
});

// æ¶ˆæ¯å¤„ç†ï¼ˆæ¼”ç¤ºç‰ˆæœ¬ï¼‰
app.post('/v1/messages', (req, res) => {
  try {
    // ç®€å•çš„è®¤è¯æ£€æŸ¥
    const apiKey = req.headers['x-api-key'];
    if (!apiKey || apiKey.length < 10) {
      return res.status(401).json({
        type: 'error',
        error: {
          type: 'authentication_error',
          message: 'Missing or invalid API key. Please provide a valid API key in the x-api-key header.'
        }
      });
    }
    
    // è½¬æ¢è¯·æ±‚
    const openaiRequest = convertAnthropicToOpenAI(req.body);
    
    // æ¨¡æ‹ŸOpenAIå“åº”ï¼ˆå®é™…ç‰ˆæœ¬ä¼šè°ƒç”¨çœŸå®çš„OpenAI APIï¼‰
    const mockOpenAIResponse = {
      id: 'chatcmpl-demo123',
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: openaiRequest.model,
      choices: [
        {
          index: 0,
          message: {
            role: 'assistant',
            content: `Hello! This is a demo response converted from ${req.body.model} to ${openaiRequest.model}. Your message was: "${openaiRequest.messages[openaiRequest.messages.length - 1].content}"`
          },
          finish_reason: 'stop'
        }
      ],
      usage: {
        prompt_tokens: 20,
        completion_tokens: 30,
        total_tokens: 50
      }
    };
    
    // è½¬æ¢å“åº”
    const anthropicResponse = convertOpenAIToAnthropic(mockOpenAIResponse, req.body.model);
    
    res.json(anthropicResponse);
    
  } catch (error) {
    let errorType = 'api_error';
    let statusCode = 500;
    
    if (error.message.includes('Missing') || error.message.includes('invalid') || error.message.includes('Unsupported')) {
      errorType = 'invalid_request_error';
      statusCode = 400;
    } else if (error.message.includes('æ”¯æŒ')) {
      errorType = 'not_supported_error';
      statusCode = 400;
    }
    
    res.status(statusCode).json({
      type: 'error',
      error: {
        type: errorType,
        message: error.message
      }
    });
  }
});

// é”™è¯¯å¤„ç†
app.use((req, res) => {
  res.status(404).json({
    type: 'error',
    error: {
      type: 'invalid_request_error',
      message: `Not found: ${req.method} ${req.path}`
    }
  });
});

// å¯åŠ¨æœåŠ¡å™¨
app.listen(PORT, () => {
  console.log('ğŸš€ OpenCC Protocol Converter (Demo Version) is running!');
  console.log(`ğŸ“¡ Server: http://localhost:${PORT}`);
  console.log('ğŸ“š API Endpoints:');
  console.log(`  - Messages: http://localhost:${PORT}/v1/messages`);
  console.log(`  - Models: http://localhost:${PORT}/v1/models`);
  console.log(`  - Health: http://localhost:${PORT}/health`);
  console.log('');
  console.log('ğŸ“– Usage Example:');
  console.log(`curl -X POST http://localhost:${PORT}/v1/messages \\`);
  console.log('  -H "Content-Type: application/json" \\');
  console.log('  -H "x-api-key: demo-api-key-12345" \\');
  console.log('  -d \'{"model": "claude-3-opus-20240229", "max_tokens": 100, "messages": [{"role": "user", "content": "Hello!"}]}\'');
  console.log('');
  console.log(`ğŸ¤– Supported Models (${Object.keys(MODEL_MAPPING).length}):`);
  Object.entries(MODEL_MAPPING).forEach(([model, mapping]) => {
    console.log(`  - ${model} â†’ ${mapping.openaiModel}`);
  });
  console.log('');
  console.log('âœ¨ Ready to convert Anthropic requests to OpenAI format!');
  console.log('');
  console.log('âš ï¸  Note: This is a demo version with mocked responses.');
  console.log('   The full TypeScript implementation is in the src/ directory.');
});